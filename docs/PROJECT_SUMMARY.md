# Flower Recognition AI Challenge - Project Summary

## é¡¹ç›®æ¦‚è¿° / Project Overview

è¿™æ˜¯ä¸€ä¸ªä¸ºèŠ±å‰è¯†åˆ«AIæŒ‘æˆ˜èµ›è®¾è®¡çš„å®Œæ•´æ·±åº¦å­¦ä¹ è§£å†³æ–¹æ¡ˆï¼Œä½¿ç”¨æœ€å…ˆè¿›çš„è®¡ç®—æœºè§†è§‰æ¨¡å‹ã€‚

This is a complete deep learning solution for the Flower Recognition AI Challenge using state-of-the-art computer vision models.

---

## ç³»ç»Ÿæ¶æ„ / System Architecture

```
FlowerRecognition/
â”œâ”€â”€ ğŸ“ configs/                    # Hydraé…ç½®æ–‡ä»¶ / Configuration files
â”‚   â”œâ”€â”€ config.yaml               # ä¸»é…ç½® / Main config
â”‚   â”œâ”€â”€ model/                    # æ¨¡å‹é…ç½® (6ç§æ¨¡å‹) / 6 model configs
â”‚   â”œâ”€â”€ dataset/                  # æ•°æ®é›†é…ç½® / Dataset config
â”‚   â”œâ”€â”€ training/                 # è®­ç»ƒé…ç½® / Training config
â”‚   â””â”€â”€ augmentation/             # æ•°æ®å¢å¼ºé…ç½® (3ç§çº§åˆ«) / 3 augmentation levels
â”‚
â”œâ”€â”€ ğŸ“ datasets/                   # æ•°æ®å¤„ç†æ¨¡å— / Data processing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ flower_dataset.py         # Datasetç±»å’Œå·¥å…· / Dataset class & utilities
â”‚
â”œâ”€â”€ ğŸ“ models/                     # æ¨¡å‹æ¨¡å— / Model architectures
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ flower_model.py           # æ¨¡å‹å®šä¹‰ / Model definitions
â”‚
â”œâ”€â”€ ğŸ“ cli/                        # å‘½ä»¤è¡Œç•Œé¢ / CLI tools
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ flower_cli.py             # CLIå‘½ä»¤ / CLI commands
â”‚
â”œâ”€â”€ ğŸ“ docs/                       # æ–‡æ¡£ / Documentation
â”‚   â”œâ”€â”€ QUICKSTART.md             # å¿«é€Ÿå¼€å§‹ (ä¸­æ–‡) / Quick start (Chinese)
â”‚   â”œâ”€â”€ USAGE_EXAMPLES.md         # ä½¿ç”¨ç¤ºä¾‹ / Usage examples
â”‚   â””â”€â”€ technical_report_template.md  # æŠ€æœ¯æŠ¥å‘Šæ¨¡æ¿ (ä¸­æ–‡) / Report template
â”‚
â”œâ”€â”€ ğŸ“„ train.py                    # è®­ç»ƒè„šæœ¬ / Training script
â”œâ”€â”€ ğŸ“„ inference.py                # æ¨ç†è„šæœ¬ / Inference script
â”œâ”€â”€ ğŸ“„ evaluate.py                 # è¯„ä¼°è„šæœ¬ / Evaluation script
â”œâ”€â”€ ğŸ“„ utils.py                    # å·¥å…·å‡½æ•° / Utility functions
â”œâ”€â”€ ğŸ“„ generate_sample_data.py    # ç”Ÿæˆæµ‹è¯•æ•°æ® / Generate test data
â”œâ”€â”€ ğŸ“„ prepare_submission.py      # å‡†å¤‡æäº¤åŒ… / Prepare submission
â”œâ”€â”€ ğŸ“„ setup.sh                    # å®‰è£…è„šæœ¬ / Setup script
â”œâ”€â”€ ğŸ“„ requirements.txt            # ä¾èµ–åˆ—è¡¨ / Dependencies
â””â”€â”€ ğŸ“„ README.md                   # é¡¹ç›®æ–‡æ¡£ / Project documentation
```

---

## æ ¸å¿ƒç‰¹æ€§ / Key Features

### 1. æ¨¡å‹æ¶æ„ / Model Architectures

æ”¯æŒ6ç§æœ€å…ˆè¿›çš„æ¨¡å‹æ¶æ„ï¼š

**è½»é‡çº§æ¨¡å‹ / Lightweight Models:**
- ConvNeXt Tiny (29M parameters) - å¿«é€Ÿå®éªŒ
- EfficientNet B3 (12M parameters) - å¹³è¡¡æ€§èƒ½

**æ ‡å‡†æ¨¡å‹ / Standard Models:**
- ConvNeXt Base (89M parameters) - æ¨èåŸºçº¿
- Swin Transformer V2 Base (88M parameters) - æœ€æ–°æ¶æ„

**é«˜ç²¾åº¦æ¨¡å‹ / High Accuracy Models:**
- EfficientNetV2-L (120M parameters) - æœ€é«˜ç²¾åº¦
- ConvNeXt Large (198M parameters) - æœ€å¤§å®¹é‡

æ‰€æœ‰æ¨¡å‹ï¼š
- âœ… å‚æ•°é‡ < 10B (ç¬¦åˆæ¯”èµ›è¦æ±‚)
- âœ… æ”¯æŒImageNeté¢„è®­ç»ƒ
- âœ… æ¨ç†æ—¶é—´ < 100ms

### 2. æ•°æ®å¢å¼º / Data Augmentation

ä¸‰ç§å¢å¼ºçº§åˆ«å¯é€‰ï¼š

**Light (è½»é‡):**
- åŸºç¡€å‡ ä½•å˜æ¢
- è½»å¾®é¢œè‰²è°ƒæ•´
- é€‚åˆå¤§æ•°æ®é›†

**Medium (ä¸­ç­‰):**
- ä¸­ç­‰å‡ ä½•å˜æ¢
- é€‚åº¦é¢œè‰²å¢å¼º
- ä¸€èˆ¬æ€§ä½¿ç”¨

**Strong (å¼ºåŠ›):**
- å¼ºåŠ›å‡ ä½•å˜æ¢ (æ—‹è½¬ã€ç¼©æ”¾ã€è£å‰ª)
- ä¸°å¯Œé¢œè‰²å¢å¼º
- é«˜çº§å¢å¼º (Cutoutã€æ¨¡ç³Šã€å™ªå£°)
- æœ€é€‚åˆå°æ•°æ®é›†

### 3. è®­ç»ƒä¼˜åŒ– / Training Optimizations

- **æ··åˆç²¾åº¦è®­ç»ƒ (AMP)**: åŠ é€Ÿè®­ç»ƒï¼Œå‡å°‘å†…å­˜
- **å­¦ä¹ ç‡è°ƒåº¦**: Cosineé€€ç« + Warmup
- **æ—©åœæœºåˆ¶**: é˜²æ­¢è¿‡æ‹Ÿåˆ
- **æ ‡ç­¾å¹³æ»‘**: æé«˜æ³›åŒ–èƒ½åŠ›
- **æ¢¯åº¦è£å‰ª**: ç¨³å®šè®­ç»ƒ
- **TensorBoardç›‘æ§**: å®æ—¶å¯è§†åŒ–

### 4. é…ç½®ç®¡ç† / Configuration Management

ä½¿ç”¨Hydraå®ç°çµæ´»çš„é…ç½®ç®¡ç†ï¼š
```bash
# ç®€å•ç»„åˆä¸åŒé…ç½®
python train.py model=convnext_base augmentation=strong training.epochs=100

# è¦†ç›–ä»»ä½•å‚æ•°
python train.py dataset.batch_size=64 training.optimizer.lr=2e-4
```

### 5. è¯„ä¼°ä¸å¯è§†åŒ– / Evaluation & Visualization

- è¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡
- æ··æ·†çŸ©é˜µ
- æ¯ç±»åˆ«å‡†ç¡®ç‡
- åˆ†ç±»æŠ¥å‘Š
- é¢„æµ‹å¯è§†åŒ–

---

## æ¯”èµ›è¦æ±‚éªŒè¯ / Competition Requirements

| è¦æ±‚ | å®ç° | çŠ¶æ€ |
|------|------|------|
| æ¨¡å‹å¤§å° < 500MB | âœ… æ‰€æœ‰æ¨¡å‹å‡ < 500MB | âœ… |
| æ¨ç†æ—¶é—´ < 100ms | âœ… åŒ…å«åŸºå‡†æµ‹è¯•å·¥å…· | âœ… |
| 100ç±»èŠ±å‰è¯†åˆ« | âœ… num_classes=100 | âœ… |
| å›¾ç‰‡å°ºå¯¸ 600Ã—600 | âœ… input_size=600 | âœ… |
| CSVè¾“å‡ºæ ¼å¼ | âœ… UTF-8, image_id,label | âœ… |
| Python 3.8+ | âœ… requirements.txt | âœ… |
| PyTorch 2.0+ | âœ… æ”¯æŒæœ€æ–°ç‰ˆæœ¬ | âœ… |

---

## å¿«é€Ÿå¼€å§‹ / Quick Start

### 1. å®‰è£… / Installation
```bash
git clone https://github.com/ironhxs/FlowerRecognition.git
cd FlowerRecognition
pip install -r requirements.txt
# or
./setup.sh
```

### 2. å‡†å¤‡æ•°æ® / Prepare Data
```bash
# ç”Ÿæˆç¤ºä¾‹æ•°æ®è¿›è¡Œæµ‹è¯•
python generate_sample_data.py

# æˆ–è€…ä½¿ç”¨æ¯”èµ›æ•°æ®
# Place your data in data/train/ and data/test/
```

### 3. è®­ç»ƒ / Training
```bash
# é»˜è®¤é…ç½®è®­ç»ƒ
python train.py

# é«˜ç²¾åº¦é…ç½®
python train.py model=efficientnet_v2_l augmentation=strong training.epochs=80
```

### 4. æ¨ç† / Inference
```bash
# ç”Ÿæˆé¢„æµ‹
python inference.py --checkpoint results/checkpoints/best_model.pt --output predictions.csv

# ä½¿ç”¨TTAæå‡å‡†ç¡®ç‡
python inference.py --checkpoint results/checkpoints/best_model.pt --output predictions.csv --tta
```

### 5. æäº¤ / Submission
```bash
# å‡†å¤‡æäº¤åŒ…
python prepare_submission.py \
    --checkpoint results/checkpoints/best_model.pt \
    --predictions predictions.csv \
    --output submission.zip
```

---

## æ¨èå·¥ä½œæµç¨‹ / Recommended Workflow

### æ–¹æ¡ˆ1ï¼šå¿«é€ŸåŸºçº¿ (1-2å°æ—¶)
```bash
# 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
python generate_sample_data.py --samples-per-class 5

# 2. å¿«é€Ÿè®­ç»ƒéªŒè¯ç³»ç»Ÿ
python train.py model=convnext_tiny training.epochs=5

# 3. æµ‹è¯•æ¨ç†
python inference.py --checkpoint results/checkpoints/best_model.pt --output test_predictions.csv
```

### æ–¹æ¡ˆ2ï¼šæ ‡å‡†è®­ç»ƒ (4-8å°æ—¶)
```bash
# 1. ä½¿ç”¨æ¯”èµ›æ•°æ®
# å°†è®­ç»ƒæ•°æ®æ”¾åœ¨ data/train/
# å°†train.csvæ”¾åœ¨ data/train.csv

# 2. è®­ç»ƒåŸºçº¿æ¨¡å‹
python train.py model=convnext_base augmentation=medium training.epochs=50

# 3. è¯„ä¼°æ¨¡å‹
python evaluate.py --checkpoint results/checkpoints/best_model.pt

# 4. ç”Ÿæˆæäº¤
python inference.py --checkpoint results/checkpoints/best_model.pt --output predictions.csv --tta
python prepare_submission.py --checkpoint results/checkpoints/best_model.pt --predictions predictions.csv
```

### æ–¹æ¡ˆ3ï¼šå†²å‡»é«˜åˆ† (1-3å¤©)
```bash
# 1. è®­ç»ƒå¤šä¸ªå¼ºåŠ›æ¨¡å‹
python train.py model=convnext_base augmentation=strong training.epochs=80 experiment_name=model1
python train.py model=efficientnet_v2_l augmentation=strong training.epochs=80 experiment_name=model2
python train.py model=swin_transformer_v2 augmentation=strong training.epochs=80 experiment_name=model3

# 2. è¯„ä¼°æ‰€æœ‰æ¨¡å‹
python evaluate.py --checkpoint results/checkpoints/model1/best_model.pt
python evaluate.py --checkpoint results/checkpoints/model2/best_model.pt
python evaluate.py --checkpoint results/checkpoints/model3/best_model.pt

# 3. ä½¿ç”¨é›†æˆæ–¹æ³•
# å‚è€ƒ docs/USAGE_EXAMPLES.md ä¸­çš„é›†æˆä»£ç 

# 4. ç”Ÿæˆæœ€ç»ˆæäº¤
python inference.py --checkpoint results/checkpoints/best/best_model.pt --output predictions.csv --tta
python prepare_submission.py --checkpoint results/checkpoints/best/best_model.pt --predictions predictions.csv
```

---

## æ€§èƒ½å‚è€ƒ / Performance Reference

åŸºäº1000æ ·æœ¬/ç±»çš„æ•°æ®é›†ï¼Œåœ¨å•ä¸ªV100 GPUä¸Šçš„å‚è€ƒæ€§èƒ½ï¼š

| æ¨¡å‹ | è®­ç»ƒæ—¶é—´/epoch | éªŒè¯å‡†ç¡®ç‡ | æ¨ç†æ—¶é—´ | æ¨¡å‹å¤§å° |
|------|---------------|-----------|---------|---------|
| ConvNeXt Tiny | ~1åˆ†é’Ÿ | 88-90% | ~30ms | 110MB |
| ConvNeXt Base | ~3åˆ†é’Ÿ | 90-92% | ~50ms | 340MB |
| EfficientNet B3 | ~2åˆ†é’Ÿ | 89-91% | ~40ms | 48MB |
| EfficientNetV2-L | ~5åˆ†é’Ÿ | 92-94% | ~70ms | 460MB |
| Swin-V2 Base | ~4åˆ†é’Ÿ | 91-93% | ~60ms | 340MB |
| ConvNeXt Large | ~5åˆ†é’Ÿ | 93-95% | ~80ms | 755MB âš ï¸ |

æ³¨ï¼šå®é™…æ€§èƒ½å–å†³äºç¡¬ä»¶å’Œæ•°æ®é›†è´¨é‡

---

## å¸¸è§é—®é¢˜ / FAQ

### Q: å¦‚ä½•é€‰æ‹©æ¨¡å‹ï¼Ÿ
A: 
- å¿«é€Ÿå®éªŒï¼šConvNeXt Tiny
- å¹³è¡¡æ€§èƒ½ï¼šConvNeXt Base (æ¨è)
- æœ€é«˜ç²¾åº¦ï¼šEfficientNetV2-L
- æœ€æ–°æ¶æ„ï¼šSwin Transformer V2

### Q: è®­ç»ƒéœ€è¦å¤šä¹…ï¼Ÿ
A: 
- å°æ•°æ®é›†(1000æ ·æœ¬)ï¼š1-2å°æ—¶
- æ ‡å‡†æ•°æ®é›†(10000æ ·æœ¬)ï¼š4-8å°æ—¶
- å®Œæ•´è®­ç»ƒ(50-100 epochs)ï¼š8-24å°æ—¶

### Q: GPUå†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
A: å‡å°æ‰¹æ¬¡å¤§å°
```bash
python train.py dataset.batch_size=16  # æˆ–æ›´å°
```

### Q: å¦‚ä½•æé«˜å‡†ç¡®ç‡ï¼Ÿ
A: 
1. ä½¿ç”¨æ›´å¼ºçš„æ•°æ®å¢å¼º
2. è®­ç»ƒæ›´å¤šè½®æ¬¡
3. å°è¯•ä¸åŒçš„æ¨¡å‹
4. ä½¿ç”¨é›†æˆæ–¹æ³•
5. ä½¿ç”¨TTA

### Q: æ¨¡å‹å¤ªå¤§è¶…è¿‡500MBï¼Ÿ
A: ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼šConvNeXt Tiny/Base æˆ– EfficientNet B3

---

## æŠ€æœ¯æ ˆ / Tech Stack

- **æ·±åº¦å­¦ä¹ æ¡†æ¶**: PyTorch 2.0+
- **æ¨¡å‹åº“**: timm (PyTorch Image Models)
- **æ•°æ®å¢å¼º**: Albumentations
- **é…ç½®ç®¡ç†**: Hydra
- **å¯è§†åŒ–**: TensorBoard, Matplotlib, Seaborn
- **è¿›åº¦æ¡**: TQDM
- **CLI**: Click, Rich

---

## å­¦æœ¯å‚è€ƒ / References

1. **ConvNeXt**: Liu et al., "A ConvNet for the 2020s", CVPR 2022
2. **EfficientNetV2**: Tan & Le, "EfficientNetV2: Smaller Models and Faster Training", ICML 2021
3. **Swin Transformer**: Liu et al., "Swin Transformer: Hierarchical Vision Transformer", ICCV 2021
4. **Albumentations**: Buslaev et al., "Albumentations: Fast and Flexible Image Augmentations", 2020

---

## æ–‡æ¡£ç´¢å¼• / Documentation Index

- **README.md**: å®Œæ•´é¡¹ç›®æ–‡æ¡£ (è‹±æ–‡)
- **docs/QUICKSTART.md**: å¿«é€Ÿå¼€å§‹æŒ‡å— (ä¸­æ–‡)
- **docs/USAGE_EXAMPLES.md**: è¯¦ç»†ä½¿ç”¨ç¤ºä¾‹
- **docs/technical_report_template.md**: æŠ€æœ¯æŠ¥å‘Šæ¨¡æ¿ (ä¸­æ–‡)

---

## æ”¯æŒä¸è”ç³» / Support & Contact

- ğŸ“§ GitHub Issues: æäº¤é—®é¢˜å’Œå»ºè®®
- ğŸ“š Documentation: æŸ¥çœ‹å®Œæ•´æ–‡æ¡£
- ğŸ’¬ Discussions: äº¤æµè®¨è®º

---

## è®¸å¯è¯ / License

MIT License - å¼€æºå…è´¹ä½¿ç”¨

---

## è‡´è°¢ / Acknowledgments

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®ï¼š
- PyTorch Team
- timm (Ross Wightman)
- Albumentations Team
- Hydra (Facebook Research)

---

**ç¥æ¯”èµ›é¡ºåˆ©ï¼Good luck with the competition! ğŸŒ¸ğŸ†**

*æœ€åæ›´æ–° / Last Updated: 2025-11-12*
