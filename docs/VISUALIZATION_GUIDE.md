# ğŸ¨ Flower Recognition - é¡¹ç›®å±•ç¤ºæŒ‡å—

æœ¬æ–‡æ¡£æä¾›äº†å¦‚ä½•ä¸ºGitHubå±•ç¤ºæ·»åŠ å¯è§†åŒ–å†…å®¹çš„æŒ‡å¯¼ã€‚

## ğŸ“¸ å»ºè®®æ·»åŠ çš„å¯è§†åŒ–å†…å®¹

### 1. ç³»ç»Ÿæ¶æ„å›¾

åˆ›å»ºä¸€ä¸ªæ¸…æ™°çš„æ¶æ„å›¾å±•ç¤ºç³»ç»Ÿå„ç»„ä»¶ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Flower Recognition System                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚      â”‚              â”‚      â”‚              â”‚
â”‚  Data Input  â”‚â”€â”€â”€â”€â”€â–¶â”‚   Training   â”‚â”€â”€â”€â”€â”€â–¶â”‚   Inference  â”‚
â”‚              â”‚      â”‚              â”‚      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚                      â”‚
       â–¼                     â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Albumentationsâ”‚      â”‚   PyTorch    â”‚      â”‚  Predictions â”‚
â”‚ Augmentation  â”‚      â”‚   + timm     â”‚      â”‚     CSV      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚                      â”‚
       â–¼                     â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 600x600 RGB  â”‚      â”‚ TensorBoard  â”‚      â”‚ 100 Classes  â”‚
â”‚   Images     â”‚      â”‚  Monitoring  â”‚      â”‚   Output     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. è®­ç»ƒæµç¨‹å›¾

```
å¼€å§‹
  â”‚
  â–¼
åŠ è½½é…ç½® (Hydra)
  â”‚
  â–¼
å‡†å¤‡æ•°æ® (FlowerDataset)
  â”‚
  â”œâ”€â–¶ è®­ç»ƒé›† (80%)
  â””â”€â–¶ éªŒè¯é›† (20%)
  â”‚
  â–¼
åˆå§‹åŒ–æ¨¡å‹ (timm)
  â”‚
  â”œâ”€â–¶ ConvNeXt Base
  â”œâ”€â–¶ EfficientNetV2-L
  â””â”€â–¶ Swin Transformer V2
  â”‚
  â–¼
è®­ç»ƒå¾ªç¯
  â”‚
  â”œâ”€â–¶ å‰å‘ä¼ æ’­ (AMP)
  â”œâ”€â–¶ è®¡ç®—æŸå¤±
  â”œâ”€â–¶ åå‘ä¼ æ’­
  â”œâ”€â–¶ æ¢¯åº¦è£å‰ª
  â”œâ”€â–¶ ä¼˜åŒ–å™¨æ›´æ–°
  â””â”€â–¶ å­¦ä¹ ç‡è°ƒåº¦
  â”‚
  â–¼
éªŒè¯é˜¶æ®µ
  â”‚
  â”œâ”€â–¶ è®¡ç®—å‡†ç¡®ç‡
  â””â”€â–¶ ä¿å­˜æœ€ä½³æ¨¡å‹
  â”‚
  â–¼
æ—©åœæ£€æŸ¥
  â”‚
  â”œâ”€â–¶ ç»§ç»­è®­ç»ƒ â”€â”€â”
  â”‚              â”‚
  â””â”€â–¶ åœæ­¢è®­ç»ƒ   â”‚
                 â”‚
                 â–¼
              ç»“æŸ
```

### 3. æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾

å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·åˆ›å»ºå›¾è¡¨ï¼š
- **matplotlib**: Pythonç»˜å›¾
- **plotly**: äº¤äº’å¼å›¾è¡¨
- **draw.io**: åœ¨çº¿å›¾è¡¨å·¥å…·
- **Excalidraw**: æ‰‹ç»˜é£æ ¼å›¾è¡¨

ç¤ºä¾‹ä»£ç ï¼š

```python
import matplotlib.pyplot as plt
import numpy as np

# æ¨¡å‹æ€§èƒ½æ•°æ®
models = ['ConvNeXt\nBase', 'EfficientNet\nV2-L', 'Swin\nV2', 'ConvNeXt\nTiny']
accuracy = [94.2, 95.8, 95.1, 92.5]
inference_time = [45, 65, 55, 25]
model_size = [340, 460, 335, 110]

# åˆ›å»ºå­å›¾
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))

# å‡†ç¡®ç‡å¯¹æ¯”
colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']
ax1.bar(models, accuracy, color=colors)
ax1.set_ylabel('Accuracy (%)', fontsize=12)
ax1.set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')
ax1.set_ylim([90, 100])
ax1.grid(axis='y', alpha=0.3)

# æ¨ç†é€Ÿåº¦å¯¹æ¯”
ax2.bar(models, inference_time, color=colors)
ax2.axhline(y=100, color='r', linestyle='--', label='Limit (100ms)')
ax2.set_ylabel('Inference Time (ms)', fontsize=12)
ax2.set_title('Inference Speed Comparison', fontsize=14, fontweight='bold')
ax2.legend()
ax2.grid(axis='y', alpha=0.3)

# æ¨¡å‹å¤§å°å¯¹æ¯”
ax3.bar(models, model_size, color=colors)
ax3.axhline(y=500, color='r', linestyle='--', label='Limit (500MB)')
ax3.set_ylabel('Model Size (MB)', fontsize=12)
ax3.set_title('Model Size Comparison', fontsize=14, fontweight='bold')
ax3.legend()
ax3.grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')
plt.show()
```

### 4. è®­ç»ƒæ›²çº¿ç¤ºä¾‹

```python
import matplotlib.pyplot as plt

# ç¤ºä¾‹è®­ç»ƒæ•°æ®
epochs = range(1, 51)
train_loss = [2.5 - 2.3 * (1 - np.exp(-x/10)) + np.random.normal(0, 0.05) for x in epochs]
val_loss = [2.5 - 2.2 * (1 - np.exp(-x/10)) + np.random.normal(0, 0.08) for x in epochs]
train_acc = [30 + 64 * (1 - np.exp(-x/10)) + np.random.normal(0, 1) for x in epochs]
val_acc = [30 + 63 * (1 - np.exp(-x/10)) + np.random.normal(0, 1.5) for x in epochs]

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# æŸå¤±æ›²çº¿
ax1.plot(epochs, train_loss, 'b-', label='Training Loss', linewidth=2)
ax1.plot(epochs, val_loss, 'r-', label='Validation Loss', linewidth=2)
ax1.set_xlabel('Epoch', fontsize=12)
ax1.set_ylabel('Loss', fontsize=12)
ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')
ax1.legend()
ax1.grid(alpha=0.3)

# å‡†ç¡®ç‡æ›²çº¿
ax2.plot(epochs, train_acc, 'b-', label='Training Accuracy', linewidth=2)
ax2.plot(epochs, val_acc, 'r-', label='Validation Accuracy', linewidth=2)
ax2.set_xlabel('Epoch', fontsize=12)
ax2.set_ylabel('Accuracy (%)', fontsize=12)
ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')
ax2.legend()
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')
plt.show()
```

### 5. æ··æ·†çŸ©é˜µç¤ºä¾‹

```python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# ç”Ÿæˆç¤ºä¾‹æ··æ·†çŸ©é˜µï¼ˆ5ç±»ä½œä¸ºæ¼”ç¤ºï¼‰
sample_classes = ['Rose', 'Tulip', 'Daisy', 'Sunflower', 'Orchid']
cm = np.array([
    [95, 2, 1, 1, 1],
    [1, 93, 3, 2, 1],
    [2, 1, 94, 2, 1],
    [1, 2, 1, 95, 1],
    [1, 2, 2, 1, 94]
])

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=sample_classes,
            yticklabels=sample_classes)
plt.xlabel('Predicted Label', fontsize=12)
plt.ylabel('True Label', fontsize=12)
plt.title('Confusion Matrix (Sample 5 Classes)', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.show()
```

### 6. æ•°æ®å¢å¼ºæ•ˆæœå±•ç¤º

å±•ç¤ºåŸå§‹å›¾åƒå’Œå¢å¼ºåçš„å›¾åƒå¯¹æ¯”ï¼š

```python
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

# åˆ›å»ºç¤ºä¾‹å›¾åƒç½‘æ ¼
fig, axes = plt.subplots(2, 4, figsize=(16, 8))

augmentation_types = [
    'Original', 'Random Crop', 'Horizontal Flip', 'Color Jitter',
    'Rotation', 'Gaussian Blur', 'Random Erasing', 'Combined'
]

for idx, (ax, aug_name) in enumerate(zip(axes.flat, augmentation_types)):
    # è¿™é‡Œåº”è¯¥åŠ è½½å®é™…çš„å¢å¼ºå›¾åƒ
    ax.set_title(aug_name, fontsize=12, fontweight='bold')
    ax.axis('off')
    ax.text(0.5, 0.5, f'{aug_name}\nExample', 
            ha='center', va='center', fontsize=10)

plt.tight_layout()
plt.savefig('augmentation_examples.png', dpi=300, bbox_inches='tight')
plt.show()
```

## ğŸ“‚ å›¾ç‰‡å­˜æ”¾ä½ç½®

å»ºè®®åœ¨é¡¹ç›®ä¸­åˆ›å»ºä»¥ä¸‹ç›®å½•ç»“æ„ï¼š

```
FlowerRecognition/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ architecture.png
â”‚   â”‚   â”œâ”€â”€ training_curves.png
â”‚   â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â””â”€â”€ augmentation_examples.png
â”‚   â”œâ”€â”€ logo/
â”‚   â”‚   â”œâ”€â”€ logo.png
â”‚   â”‚   â””â”€â”€ banner.png
â”‚   â””â”€â”€ demo/
â”‚       â”œâ”€â”€ demo_video.gif
â”‚       â””â”€â”€ inference_demo.gif
```

## ğŸ“ åœ¨READMEä¸­æ·»åŠ å›¾ç‰‡

åœ¨README.mdä¸­å¼•ç”¨å›¾ç‰‡ï¼š

```markdown
## ğŸ¯ ç³»ç»Ÿæ¶æ„

![ç³»ç»Ÿæ¶æ„](assets/images/architecture.png)

## ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”

![æ¨¡å‹å¯¹æ¯”](assets/images/model_comparison.png)

## ğŸ“ˆ è®­ç»ƒæ›²çº¿

![è®­ç»ƒæ›²çº¿](assets/images/training_curves.png)

## ğŸ¨ æ•°æ®å¢å¼ºæ•ˆæœ

![æ•°æ®å¢å¼º](assets/images/augmentation_examples.png)
```

## ğŸ¬ åˆ›å»ºæ¼”ç¤ºGIF

ä½¿ç”¨ä»¥ä¸‹å·¥å…·åˆ›å»ºæ¼”ç¤ºGIFï¼š

1. **ScreenToGif** (Windows)
2. **Kap** (macOS)
3. **Peek** (Linux)
4. **LICEcap** (è·¨å¹³å°)

æ¼”ç¤ºå†…å®¹å»ºè®®ï¼š
- è®­ç»ƒè¿‡ç¨‹çš„TensorBoardç•Œé¢
- æ¨¡å‹æ¨ç†çš„å‘½ä»¤è¡Œè¾“å‡º
- é¢„æµ‹ç»“æœçš„å¯è§†åŒ–

## ğŸŒ åœ¨çº¿å·¥å…·æ¨è

### å›¾è¡¨åˆ›å»º
- **draw.io**: https://app.diagrams.net/
- **Excalidraw**: https://excalidraw.com/
- **Mermaid Live Editor**: https://mermaid.live/

### å¾½ç« ç”Ÿæˆ
- **Shields.io**: https://shields.io/

### GIFä¼˜åŒ–
- **ezgif.com**: https://ezgif.com/

## ğŸ’¡ å±•ç¤ºæŠ€å·§

1. **ä½¿ç”¨é«˜è´¨é‡å›¾ç‰‡**ï¼šè‡³å°‘300 DPI
2. **ä¿æŒä¸€è‡´çš„é£æ ¼**ï¼šç»Ÿä¸€é…è‰²æ–¹æ¡ˆ
3. **æ·»åŠ è¯´æ˜æ–‡å­—**ï¼šè®©å›¾ç‰‡æ˜“äºç†è§£
4. **ä¼˜åŒ–æ–‡ä»¶å¤§å°**ï¼šé¿å…ä»“åº“è¿‡å¤§
5. **ä½¿ç”¨ç›¸å¯¹è·¯å¾„**ï¼šä¾¿äºç»´æŠ¤

## ğŸ¨ é…è‰²æ–¹æ¡ˆå»ºè®®

æ¨èä½¿ç”¨ä»¥ä¸‹é…è‰²ï¼ˆä¸READMEå¾½ç« ä¸€è‡´ï¼‰ï¼š

- **è“è‰²** (ä¸»è‰²): `#3498db` - ç”¨äºè®­ç»ƒç›¸å…³
- **çº¢è‰²** (æ¬¡è‰²): `#e74c3c` - ç”¨äºéªŒè¯ç›¸å…³
- **ç»¿è‰²** (æˆåŠŸ): `#2ecc71` - ç”¨äºæˆåŠŸçŠ¶æ€
- **æ©™è‰²** (è­¦å‘Š): `#f39c12` - ç”¨äºè­¦å‘Šä¿¡æ¯
- **ç´«è‰²** (ç‰¹è‰²): `#9b59b6` - ç”¨äºç‰¹æ®ŠåŠŸèƒ½

## ğŸ“‹ æ£€æŸ¥æ¸…å•

åˆ›å»ºå¯è§†åŒ–å†…å®¹åï¼Œç¡®ä¿ï¼š

- [ ] æ‰€æœ‰å›¾ç‰‡éƒ½å·²æ·»åŠ åˆ°`assets/`ç›®å½•
- [ ] READMEä¸­æ­£ç¡®å¼•ç”¨äº†æ‰€æœ‰å›¾ç‰‡
- [ ] å›¾ç‰‡æ–‡ä»¶å¤§å°åˆç†ï¼ˆå•ä¸ª<2MBï¼‰
- [ ] å›¾ç‰‡æ¸…æ™°å¯è¯»
- [ ] æ·»åŠ äº†å›¾ç‰‡è¯´æ˜æ–‡å­—
- [ ] åœ¨ä¸åŒè®¾å¤‡ä¸Šæµ‹è¯•æ˜¾ç¤ºæ•ˆæœ
- [ ] æ›´æ–°äº†`.gitignore`ï¼ˆå¦‚æœéœ€è¦ï¼‰

---

é€šè¿‡æ·»åŠ è¿™äº›å¯è§†åŒ–å†…å®¹ï¼Œä½ çš„GitHubé¡¹ç›®å°†æ›´åŠ ä¸“ä¸šå’Œå¸å¼•äººï¼ğŸŒŸ
