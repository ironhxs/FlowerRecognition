#!/bin/bash
# Hydra è¶…å‚æ•°æ‰«æè„šæœ¬
# è‡ªåŠ¨è¿è¡Œå¤šä¸ªå®éªŒï¼Œå¯»æ‰¾æœ€ä½³è¶…å‚æ•°ç»„åˆ

set -e

echo "========================================================================"
echo "ğŸ” Swin V2 è¶…å‚æ•°æ‰«æ"
echo "========================================================================"
echo ""
echo "æ‰«æèŒƒå›´:"
echo "  - Learning Rate: 1.0e-5, 1.5e-5, 2.0e-5, 2.5e-5"
echo "  - Weight Decay: 0.12, 0.15, 0.18"
echo "  - Label Smoothing: 0.15, 0.2"
echo "  - Drop Path Rate: 0.3, 0.35"
echo ""
echo "æ€»å®éªŒæ•°: 4 Ã— 3 Ã— 2 Ã— 2 = 48 ç»„åˆ"
echo "æ¯ç»„ 30 epochsï¼Œé¢„è®¡æ€»æ—¶é—´: ~40 å°æ—¶"
echo ""
read -p "ç¡®è®¤å¼€å§‹æ‰«æ? (y/n) " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "å·²å–æ¶ˆ"
    exit 0
fi
echo "========================================================================"
echo ""

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p /root/autodl-tmp/checkpoints_sweep
mkdir -p /root/tf-logs/sweep

# å¯åŠ¨ TensorBoard
echo "ğŸ“Š å¯åŠ¨ TensorBoard..."
kill $(lsof -t -i:6006) 2>/dev/null || true
tensorboard --logdir /root/tf-logs/sweep --port 6006 --bind_all > /dev/null 2>&1 &
echo "âœ… TensorBoard: http://localhost:6006"
echo ""

# å¼€å§‹æ‰«æ
echo "ğŸš€ å¼€å§‹è¶…å‚æ•°æ‰«æ..."
echo "========================================================================"
echo ""

python train.py -cn sweep_lr --multirun \
  hydra.sweep.dir=/root/autodl-tmp/sweep_outputs \
  hydra.sweep.subdir='lr=${training.optimizer.lr}_wd=${training.optimizer.weight_decay}_ls=${training.label_smoothing}_dp=${training.drop_path_rate}'

echo ""
echo "========================================================================"
echo "âœ… è¶…å‚æ•°æ‰«æå®Œæˆï¼"
echo ""
echo "æŸ¥çœ‹ç»“æœ:"
echo "  1. TensorBoard: http://localhost:6006 (å¯¹æ¯”æ‰€æœ‰å®éªŒæ›²çº¿)"
echo "  2. è¾“å‡ºç›®å½•: /root/autodl-tmp/sweep_outputs/"
echo "  3. Logs: /root/tf-logs/sweep/"
echo ""
echo "ä¸‹ä¸€æ­¥: æ‰¾å‡º Val Acc æœ€é«˜çš„é…ç½®ï¼Œæ›´æ–°åˆ° swin_anti_overfit.yaml"
echo "========================================================================"
